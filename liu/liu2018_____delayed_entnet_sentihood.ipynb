{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "liu2018_____delayed_entnet_sentihood.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMAMtCb1Vod5",
        "colab_type": "text"
      },
      "source": [
        "# 1. Delayed EntNet Sentihood (Constructor)<br>\n",
        "\n",
        "Parametros:\n",
        "\n",
        "* (atributo) batch_size: cantidad de ejemplos de entrenamiento utilizados en una iteracion\n",
        "* (atributo) vocab_size: cantidad de palabras en el vocabulario del archivo de embeddings\n",
        "* (atributo) target_len: tamaño de los objetivos (entidades)\n",
        "* (atributo) aspect_len: tamaño de los aspectos\n",
        "* (atributo) sentence_len: tamaño de la oracion mas larga del dataset\n",
        "* (atributo) answer_size: tamaño del vector de salida (3 porque las categorias son: positivo, negativo, ninguno)\n",
        "* (atributo) embedding_size: tamaño de los vectores de embedding\n",
        "* (atributo) embedding_mat: conjunto de vectores de embeddings\n",
        "* (atributo) update_embeddings: cambiar o no los embeddings (bool)\n",
        "* softmax_mask: aplicar una mascara o no a las operaciones con softmax\n",
        "* (atributo) max_grad_norm: para evitar que la gradiente crezca demasido y se produzcan NaN\n",
        "* (atributo) n_keys: numero de cadenas por cada objetivo (entidad) con embedding (key)\n",
        "* (atributo) tied_keys: los embeddings (keys) de los objetivos (entidades)\n",
        "* (atributo) l2_final_layer: lambda de L2 Norm (minimos cuadrados)\n",
        "* (atributo) initializer: forma de inicializar los pesos de la red neuronal\n",
        "* (atributo) optimizer: metodo para actualizar los pesos en cada iteracion (en vez de usar gradiente decendiente)\n",
        "* (atributo) session: sesion de tensorflow\n",
        "* (atributo) name: nombre del modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKl8MvPlTYIa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Delayed_EntNet_Sentihood(object):\n",
        "    def __init__(self, \n",
        "        batch_size, vocab_size, target_len, aspect_len, sentence_len, \n",
        "        answer_size, embedding_size,\n",
        "        weight_tying=\"adj\",\n",
        "        hops=3,\n",
        "        embedding_mat=None,\n",
        "        update_embeddings=False,\n",
        "        softmax_mask=True,\n",
        "        max_grad_norm=5.0,\n",
        "        n_keys=6,\n",
        "        tied_keys=[],\n",
        "        l2_final_layer=0.0,\n",
        "        initializer=tf.contrib.layers.xavier_initializer(),\n",
        "        optimizer=tf.train.AdamOptimizer(learning_rate=1e-2),\n",
        "        global_step=None,\n",
        "        session=None,\n",
        "        name='Delayed_EntNet_Sentihood'):\n",
        "\n",
        "        print name\n",
        "\n",
        "        self._batch_size = batch_size\n",
        "        self._vocab_size = vocab_size\n",
        "        self._target_len = target_len\n",
        "        self._aspect_len = aspect_len\n",
        "        self._sentence_len = sentence_len\n",
        "        self._embedding_size = embedding_size\n",
        "        self._answer_size = answer_size\n",
        "        self._max_grad_norm = max_grad_norm\n",
        "        self._init = initializer\n",
        "        self._opt = optimizer\n",
        "        self._global_step = global_step\n",
        "        self._name = name\n",
        "        self._embedding_mat = embedding_mat\n",
        "        self._update_embeddings = update_embeddings\n",
        "\n",
        "        assert len(tied_keys) <= n_keys\n",
        "        self._n_keys = n_keys\n",
        "        self._tied_keys = tied_keys\n",
        "        self._l2_final_layer = l2_final_layer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9TsqXjigjZo",
        "colab_type": "text"
      },
      "source": [
        "Metodos:\n",
        "\n",
        "* build_inputs: crea los placeholders que el modelo va a usar (Seccion 2)\n",
        "* build_vars: crea las variables que el modelo va a usar (Seccion 3)\n",
        "* inference_adj: (Seccion 4)\n",
        "\n",
        "Atributos:\n",
        "\n",
        "* self._sentences: placeholder del tamaño mas grande de una oracion en el dataset\n",
        "* self._targets: placeholder del tamaño mas grande de un objetivo (entidad)\n",
        "* self._aspects: placeholder del tamaño mas grande de un aspecto\n",
        "* self._entnet_input_keep_prob: probabilidad de mantener un nodo en la entrada para evitar overfit\n",
        "* self._entnet_output_keep_prob: probabilidad de mantener un nodo en la salida para evitar overfit\n",
        "* self._entnet_state_keep_prob: probabilidad de mantener un nodo en los estados para evitar overfit\n",
        "* self._final_layer_keep_prob: probabilidad de mantener un nodo en la capa final para evitar overfit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgg6KLMsgSaV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "        self._build_inputs()\n",
        "        self._build_vars()\n",
        "\n",
        "        logits = self._inference_adj(\n",
        "            self._sentences, \n",
        "            self._targets,\n",
        "            self._aspects,\n",
        "            self._entnet_input_keep_prob,\n",
        "            self._entnet_output_keep_prob,\n",
        "            self._entnet_state_keep_prob,\n",
        "            self._final_layer_keep_prob,\n",
        "        )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TO70z2giipFG",
        "colab_type": "text"
      },
      "source": [
        "cross entropy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aie58HfEikLy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "        cross_entropy = tf.nn.softmax_cross_entropy_with_logits(\n",
        "            logits=logits, labels=tf.cast(self._answers_one_hot, tf.float32), \n",
        "            name=\"cross_entropy\"\n",
        "        )\n",
        "        cross_entropy_mean = tf.reduce_mean(\n",
        "            cross_entropy, name=\"cross_entropy_mean\"\n",
        "        )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v61nUA1QifB3",
        "colab_type": "text"
      },
      "source": [
        "regularizacion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0mzs2sDiXYo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "        # l2 regularization\n",
        "        trainable_variables = tf.trainable_variables()\n",
        "        l2_loss_final_layer = 0.0\n",
        "        assert self._l2_final_layer >= 0\n",
        "\n",
        "        if self._l2_final_layer > 0:\n",
        "            final_layer_weights = [ tf.nn.l2_loss(v) for v in trainable_variables\n",
        "                                    if 'R:0' in v.name]\n",
        "            assert len(final_layer_weights) == 1\n",
        "            l2_loss_final_layer = self._l2_final_layer * tf.add_n(final_layer_weights)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yANr82mzjbnO",
        "colab_type": "text"
      },
      "source": [
        "perdida"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URL3Iafpjdy8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "        # loss op\n",
        "        loss_op = cross_entropy_mean + l2_loss_final_layer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "giwOrKsqjkAR",
        "colab_type": "text"
      },
      "source": [
        "gradiente"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9edSha8jkNY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "        # gradient pipeline\n",
        "        grads_and_vars = self._opt.compute_gradients(loss_op)\n",
        "\n",
        "        grads_and_vars = [(tf.clip_by_norm(g, self._max_grad_norm), v) for g,v in grads_and_vars]\n",
        "        nil_grads_and_vars = []\n",
        "        \n",
        "        for g, v in grads_and_vars:\n",
        "            if v.name in self._nil_vars:\n",
        "                nil_grads_and_vars.append((zero_nil_slot(g), v))\n",
        "            else:\n",
        "                nil_grads_and_vars.append((g, v))\n",
        "        \n",
        "        train_op = self._opt.apply_gradients(nil_grads_and_vars, global_step=self._global_step, name=\"train_op\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fd4e0PsbjrUi",
        "colab_type": "text"
      },
      "source": [
        "prediccion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_WUY8ivjrlc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "        # predict ops\n",
        "        predict_op = tf.argmax(logits, 1, name=\"predict_op\")\n",
        "        predict_proba_op = tf.nn.softmax(logits, name=\"predict_proba_op\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSn-gQdgjwvN",
        "colab_type": "text"
      },
      "source": [
        "Atributos:\n",
        "\n",
        "* self.loss_op = loss_op\n",
        "* self.predict_op = predict_op\n",
        "* self.predict_proba_op = predict_proba_op\n",
        "* self.train_op = train_op"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Y7GELpNjw-n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "        # assign ops\n",
        "        self.loss_op = loss_op\n",
        "        self.predict_op = predict_op\n",
        "        self.predict_proba_op = predict_proba_op\n",
        "        self.train_op = train_op\n",
        "\n",
        "        init_op = tf.global_variables_initializer()\n",
        "        self._sess = session\n",
        "        self._sess.run(init_op, feed_dict={self._input_embedding: self._embedding_mat})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COeYdq9GV8X5",
        "colab_type": "text"
      },
      "source": [
        "# 2. Build inputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wvp5P7VqdtH",
        "colab_type": "text"
      },
      "source": [
        "* (atributo) sentences: placeholder del tamaño mas grande de una oracion en el dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSjMwfAKUaCG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    def _build_inputs(self):\n",
        "        self._sentences = tf.placeholder(\n",
        "            tf.int32, [None, self._sentence_len], \n",
        "            name=\"sentences\"\n",
        "        )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDV9u-NtqilH",
        "colab_type": "text"
      },
      "source": [
        "* (atributo) targets: placeholder del tamaño mas grande de un objetivo (entidad)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MbH513FQp6pQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "        self._targets = tf.placeholder(\n",
        "            tf.int32, [None, self._target_len],\n",
        "            name=\"targets\"\n",
        "        )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEpOnwLGqoDw",
        "colab_type": "text"
      },
      "source": [
        "* (atributo) aspects: placeholder del tamaño mas grande de un aspecto"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTMOIlf9p_MV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "        self._aspects = tf.placeholder(\n",
        "            tf.int32, [None, self._aspect_len],\n",
        "            name=\"aspects\"\n",
        "        )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGEvJRtfqvQW",
        "colab_type": "text"
      },
      "source": [
        "* (atributo) answers: placeholder para los indices de las salidas (positivo, negativo, ninguno)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHYPKo58qByd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "        self._answers = tf.placeholder(\n",
        "            tf.int32, [None], \n",
        "            name=\"answers\"\n",
        "        )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GdBrl8YMqzes",
        "colab_type": "text"
      },
      "source": [
        "* (atributo) answers_one_hot: representacion one hot de las salidas (positivo, negativo, ninguno)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwjSa39GqMY1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "        self._answers_one_hot = tf.one_hot(\n",
        "            indices=self._answers,\n",
        "            depth=self._answer_size,\n",
        "        )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7tRozVcArASb",
        "colab_type": "text"
      },
      "source": [
        "* (atributo) input_embedding: placeholder para el conjunto de vectores de embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "av7s7fv-qOSf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "        self._input_embedding = tf.placeholder(\n",
        "            tf.float32, shape=self._embedding_mat.shape,\n",
        "            name=\"input_embedding\"\n",
        "        )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTJFzaO-rE3b",
        "colab_type": "text"
      },
      "source": [
        "* (atributo) entnet_input_keep_prob: probabilidad de mantener un nodo en la entrada para evitar overfit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "snM45dnEqSw0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "        self._entnet_input_keep_prob = tf.placeholder(\n",
        "            tf.float32, shape=[],\n",
        "            name=\"entnet_input_keep_prob\"\n",
        "        )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rzyNUS1rMPl",
        "colab_type": "text"
      },
      "source": [
        "* (atributo) entnet_output_keep_prob: probabilidad de mantener un nodo en la salida para evitar overfit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_krFTrIZqU8t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "        self._entnet_output_keep_prob = tf.placeholder(\n",
        "            tf.float32, shape=[],\n",
        "            name=\"entnet_output_keep_prob\"\n",
        "        )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tH8dRJBrRsI",
        "colab_type": "text"
      },
      "source": [
        "* (atributo) entnet_state_keep_prob: probabilidad de mantener un nodo en los estados para evitar overfit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZiPQCYjCqXCy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "        self._entnet_state_keep_prob = tf.placeholder(\n",
        "            tf.float32, shape=[],\n",
        "            name=\"entnet_state_keep_prob\"\n",
        "        )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2l7GoZmqrWA9",
        "colab_type": "text"
      },
      "source": [
        "* (atributo) final_layer_keep_prob: probabilidad de mantener un nodo en la capa final para evitar overfit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mpNTtJpqagE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "        self._final_layer_keep_prob = tf.placeholder(\n",
        "            tf.float32, shape=[],\n",
        "            name=\"final_layer_keep_prob\"\n",
        "        )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NdZv_rt6WS85",
        "colab_type": "text"
      },
      "source": [
        "# 3. Build vars<br>\n",
        "\n",
        "Atributos:\n",
        "\n",
        "* self._embedding: variable del conjunto de vectores de embeddings\n",
        "* self._free_keys_embedding: variable con keys extra"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNBIrMIWU8oc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    def _build_vars(self):\n",
        "        with tf.variable_scope(self._name):\n",
        "            self._embedding = tf.get_variable(\n",
        "                name=\"embedding\", # Nueva variable\n",
        "                dtype=tf.float32,\n",
        "                initializer=self._input_embedding, # Conjunto de vectores de embeddings\n",
        "                trainable=self._update_embeddings, # Cambiar o no los embeddings (bool)\n",
        "            )\n",
        "\n",
        "            self._free_keys_embedding = tf.get_variable(\n",
        "                name=\"free_keys_embedding\", # Nueva variable\n",
        "                dtype=tf.float32,\n",
        "                shape=[self._n_keys - len(self._tied_keys), self._embedding_size], # keys extra\n",
        "                initializer=self._init, # Inicializador de pesos\n",
        "                trainable=True,\n",
        "            )\n",
        "\n",
        "        self._nil_vars = set([self._embedding.name])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNkUbv5FWa25",
        "colab_type": "text"
      },
      "source": [
        "# 4. Mask embedding<br>\n",
        "\n",
        "Parametros:\n",
        " \n",
        " * embedding: variable del conjunto de vectores de embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLxpZZoQVDsL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    def _mask_embedding(self, embedding):\n",
        "        vocab_size, embedding_size = self._embedding_mat.shape\n",
        "        embedding_mask = tf.constant(\n",
        "            value=[0 if i == 0 else 1 for i in range(vocab_size)],\n",
        "            shape=[vocab_size, 1],\n",
        "            dtype=tf.float32,\n",
        "            name=\"embedding_mask\",\n",
        "        )\n",
        "        return embedding * embedding_mask"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "peMBRbcbWniZ",
        "colab_type": "text"
      },
      "source": [
        "# 5. Inference adj<br>\n",
        "\n",
        "Parametros:\n",
        "\n",
        "* sentences: placeholder del tamaño mas grande de una oracion en el dataset\n",
        "* targets: placeholder del tamaño mas grande de un objetivo (entidad)\n",
        "* aspects: placeholder del tamaño mas grande de un aspecto\n",
        "* entnet_input_keep_prob: probabilidad de mantener un nodo en la entrada para evitar overfit\n",
        "* entnet_output_keep_prob: probabilidad de mantener un nodo en la salida para evitar overfit\n",
        "* entnet_state_keep_prob: probabilidad de mantener un nodo en los estados para evitar overfit\n",
        "* final_layer_keep_prob: probabilidad de mantener un nodo en la capa final para evitar overfit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jg0O94gHVSdw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    def _inference_adj(self, sentences, targets, aspects, \n",
        "                       entnet_input_keep_prob, entnet_output_keep_prob, \n",
        "                       entnet_state_keep_prob, final_layer_keep_prob):\n",
        "    \n",
        "        with tf.variable_scope(self._name):\n",
        "            masked_embedding = self._mask_embedding(self._embedding)\n",
        "\n",
        "            batch_size = tf.shape(sentences)[0]\n",
        "            \n",
        "            targets_emb = tf.nn.embedding_lookup(masked_embedding, targets)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wcw_xkhAuEEV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "            # [None, entity_size, emb_size]\n",
        "            targets_emb = tf.reduce_mean(\n",
        "                input_tensor=targets_emb,\n",
        "                axis=1,\n",
        "                keep_dims=True,\n",
        "            )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJx3_NEBuLeu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "            # [None, 1, emb_size]\n",
        "            aspects_emb = tf.nn.embedding_lookup(masked_embedding, aspects)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWkw5TiKuRuX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "            # [None, aspect_size, emb_size]\n",
        "            aspects_emb = tf.reduce_mean(\n",
        "                input_tensor=aspects_emb,\n",
        "                axis=1,\n",
        "                keep_dims=True,\n",
        "            )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FS3fwP5vuXdG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "            # [None, 1, emb_size]\n",
        "            sentences_emb = tf.nn.embedding_lookup(masked_embedding, sentences)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-TwhTkdufiK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "            # [None, memory_size, emb_size]\n",
        "            sentences_len = self._sentence_length(sentences_emb)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xS9GfZTZuvuD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "            # [None]\n",
        "            tied_keys_emb = tf.nn.embedding_lookup(masked_embedding, self._tied_keys)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kg036mv1u1dD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "            # [len(self._tied_keys), max_key_len, emb_size]\n",
        "            tied_keys_emb = tf.reduce_mean(\n",
        "                input_tensor=tied_keys_emb,\n",
        "                axis=1,\n",
        "            )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8Z6EA8Gu6Tn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "            # [len(self._tied_keys), emb_size]\n",
        "            free_keys_emb = self._free_keys_embedding"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CD5xnbiwvC9D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "            # [n_keys - len(self._tied_keys), emb_size]\n",
        "            keys_emb = tf.concat(\n",
        "                values=[tied_keys_emb, free_keys_emb],\n",
        "                axis=0,\n",
        "                name=\"keys_emb\",\n",
        "            )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgIvhcGNvIi-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "            # [n_keys, emb_size]\n",
        "            batched_keys_emb = tf.tile(\n",
        "                input=tf.expand_dims(input=keys_emb, axis=0),\n",
        "                multiples=[batch_size, 1, 1]\n",
        "            )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LINROTYvVrC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "            # [None, n_keys, emb_size]\n",
        "            keys = tf.split(keys_emb, self._n_keys, axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mg0oWyC-vdoJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "            # list of [1, emb_size]\n",
        "            keys = [tf.squeeze(key, axis=0) for key in keys]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vF_EQ7NdvtHs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "            # list of [emb_size]\n",
        "            alpha = tf.get_variable(\n",
        "                name='alpha',\n",
        "                shape=self._embedding_size,\n",
        "                initializer=tf.constant_initializer(1.0)\n",
        "            )\n",
        "    \n",
        "            activation = partial(prelu, alpha=alpha)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mI3AimCywCMX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "            cell_fw = DynamicMemoryCell(\n",
        "                num_blocks=self._n_keys,\n",
        "                num_units_per_block=self._embedding_size,\n",
        "                keys=keys,\n",
        "                initializer=self._init,\n",
        "                recurrent_initializer=self._init,\n",
        "                activation=activation,\n",
        "            )\n",
        "  \n",
        "            initial_state_fw = cell_fw.zero_state(batch_size, tf.float32)\n",
        "            sentences_emb_shape = sentences_emb.get_shape()\n",
        "      \n",
        "            cell_fw = tf.contrib.rnn.DropoutWrapper(\n",
        "                cell=cell_fw,\n",
        "                input_keep_prob=entnet_input_keep_prob,\n",
        "                output_keep_prob=entnet_output_keep_prob,\n",
        "                state_keep_prob=entnet_state_keep_prob,\n",
        "                variational_recurrent=True,\n",
        "                input_size=(sentences_emb_shape[2]),\n",
        "                dtype=tf.float32,\n",
        "            )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDPS6VQZwoki",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "            cell_bw = DynamicMemoryCell(\n",
        "                num_blocks=self._n_keys,\n",
        "                num_units_per_block=self._embedding_size,\n",
        "                keys=keys,\n",
        "                initializer=self._init,\n",
        "                recurrent_initializer=self._init,\n",
        "                activation=activation,\n",
        "            )\n",
        "  \n",
        "            initial_state_bw = cell_bw.zero_state(batch_size, tf.float32)\n",
        "    \n",
        "            cell_bw = tf.contrib.rnn.DropoutWrapper(\n",
        "                cell=cell_bw,\n",
        "                input_keep_prob=entnet_input_keep_prob,\n",
        "                output_keep_prob=entnet_output_keep_prob,\n",
        "                state_keep_prob=entnet_state_keep_prob,\n",
        "                variational_recurrent=True,\n",
        "                input_size=(sentences_emb_shape[2]),\n",
        "                dtype=tf.float32,\n",
        "            )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RV_z8P0XxGqU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "            (_, _), (last_state_fw, last_state_bw) = tf.nn.bidirectional_dynamic_rnn(\n",
        "                cell_fw=cell_fw,\n",
        "                cell_bw=cell_bw,\n",
        "                inputs=sentences_emb,\n",
        "                sequence_length=sentences_len,\n",
        "                initial_state_fw=initial_state_fw,\n",
        "                initial_state_bw=initial_state_bw,\n",
        "            )\n",
        "\n",
        "            last_state_fw, _ = tf.split(\n",
        "                value=last_state_fw,\n",
        "                num_or_size_splits=[\n",
        "                    self._n_keys * self._embedding_size, \n",
        "                    self._n_keys * self._embedding_size,\n",
        "                ],\n",
        "                axis=1\n",
        "            )\n",
        "    \n",
        "            last_state_bw, _ = tf.split(\n",
        "                value=last_state_bw,\n",
        "                num_or_size_splits=[\n",
        "                    self._n_keys * self._embedding_size, \n",
        "                    self._n_keys * self._embedding_size,\n",
        "                ],\n",
        "                axis=1\n",
        "            )\n",
        "      \n",
        "            # last_state_f/bw: [None, emb_size * n_keys]\n",
        "            last_state_fw = tf.stack(\n",
        "                tf.split(last_state_fw, self._n_keys, axis=1), axis=1)\n",
        "            \n",
        "            # [None, n_keys, emb_size]\n",
        "            last_state_bw = tf.stack(\n",
        "                tf.split(last_state_bw, self._n_keys, axis=1), axis=1)\n",
        "            \n",
        "            # [None, n_keys, emb_size]\n",
        "            last_state = last_state_fw + last_state_bw"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpum-YLFxaXH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "            # [None, n_keys, emb_size]\n",
        "            asp_att = tf.concat(values=[targets_emb, aspects_emb], axis=2)\n",
        "    \n",
        "            # [None, 1, emb_size * 2]\n",
        "            W_asp_att = tf.get_variable(\n",
        "                name='W_asp_att',\n",
        "                shape=[self._embedding_size, self._embedding_size * 2],\n",
        "                dtype=tf.float32,\n",
        "                initializer=self._init,\n",
        "            )\n",
        "        \n",
        "            temp = tf.tensordot(\n",
        "                batched_keys_emb, W_asp_att, [[2], [0]]\n",
        "            )\n",
        "          \n",
        "            # [None, n_keys, emb_size * 2]\n",
        "            attention = tf.reduce_sum(temp * asp_att, axis=2)\n",
        "            # [None, n_keys]\n",
        "            attention_max = tf.reduce_max(attention, axis=-1, keep_dims=True)\n",
        "            # [None, 1]\n",
        "            attention = tf.nn.softmax(attention - attention_max)\n",
        "            # [None, n_keys]\n",
        "            attention = tf.expand_dims(attention, axis=2)\n",
        "            # [None, n_keys, 1]\n",
        "\n",
        "            u = tf.reduce_sum(last_state * attention, axis=1)\n",
        "            # [None, emb_size]\n",
        "            \n",
        "            R = tf.get_variable('R', [self._embedding_size, self._answer_size])\n",
        "            H = tf.get_variable('H', [self._embedding_size, self._embedding_size])\n",
        "\n",
        "            a = tf.squeeze(aspects_emb, axis=1)\n",
        "            # [None, emb_size]\n",
        "            hidden = activation(a + tf.matmul(u, H))\n",
        "            # [None, emb)size]\n",
        "            hidden = tf.nn.dropout(x=hidden, keep_prob=final_layer_keep_prob)\n",
        "            # [None, emb_size]\n",
        "            y = tf.matmul(hidden, R)\n",
        "            # [None, 1]\n",
        "\n",
        "            return y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvOXmWbqW4Ki",
        "colab_type": "text"
      },
      "source": [
        "# 6. Get mini batch start end<br>\n",
        "\n",
        "Parametros:\n",
        "\n",
        "* n_train: \n",
        "* batch_size: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aSa4dj_VYtJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    def _get_mini_batch_start_end(self, n_train, batch_size=None):\n",
        "        '''\n",
        "        Args:\n",
        "            n_train: int, number of training instances\n",
        "            batch_size: int (or None if full batch)\n",
        "        \n",
        "        Returns:\n",
        "            batches: list of tuples of (start, end) of each mini batch\n",
        "        '''\n",
        "        mini_batch_size = n_train if batch_size is None else batch_size\n",
        "        batches = zip(\n",
        "            range(0, n_train, mini_batch_size),\n",
        "            list(range(mini_batch_size, n_train, mini_batch_size)) + [n_train]\n",
        "        )\n",
        "        return batches"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8rltyazW-XL",
        "colab_type": "text"
      },
      "source": [
        "# 7. Fit\n",
        "\n",
        "Parametros:\n",
        "\n",
        "* sentences: placeholder del tamaño mas grande de una oracion en el dataset\n",
        "* targets: placeholder del tamaño mas grande de un objetivo (entidad)\n",
        "* aspects: placeholder del tamaño mas grande de un aspecto\n",
        "* entnet_input_keep_prob: probabilidad de mantener un nodo en la entrada para evitar overfit\n",
        "* entnet_output_keep_prob: probabilidad de mantener un nodo en la salida para evitar overfit\n",
        "* entnet_state_keep_prob: probabilidad de mantener un nodo en los estados para evitar overfit\n",
        "* final_layer_keep_prob: probabilidad de mantener un nodo en la capa final para evitar overfit\n",
        "* batch_size: cantidad de ejemplos de entrenamiento utilizados en una iteracion\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlM2C82VVcbS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    def fit(self, sentences, targets, aspects, answers, entnet_input_keep_prob, \n",
        "            entnet_output_keep_prob, entnet_state_keep_prob, \n",
        "            final_layer_keep_prob, batch_size=None):\n",
        "    \n",
        "        assert len(sentences) == len(targets)\n",
        "        assert len(sentences) == len(aspects)\n",
        "        assert len(sentences) == len(answers)\n",
        "        \n",
        "        batches = self._get_mini_batch_start_end(len(sentences), batch_size)\n",
        "        total_loss = 0.\n",
        "        \n",
        "        for start, end in batches:\n",
        "            feed_dict = {\n",
        "                self._sentences: sentences[start:end], \n",
        "                self._targets: targets[start:end],\n",
        "                self._aspects: aspects[start:end],\n",
        "                self._answers: answers[start:end], \n",
        "                self._entnet_input_keep_prob: entnet_input_keep_prob,\n",
        "                self._entnet_output_keep_prob: entnet_output_keep_prob,\n",
        "                self._entnet_state_keep_prob: entnet_state_keep_prob,\n",
        "                self._final_layer_keep_prob: final_layer_keep_prob,\n",
        "            }\n",
        "            loss, _ = self._sess.run(\n",
        "                [self.loss_op, self.train_op], \n",
        "                feed_dict=feed_dict\n",
        "            )\n",
        "            total_loss = loss * len(sentences[start:end])\n",
        "        return total_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FU3keGNPXEjr",
        "colab_type": "text"
      },
      "source": [
        "# 8. Predict<br>\n",
        "\n",
        "Parametros:\n",
        "\n",
        "* sentences: placeholder del tamaño mas grande de una oracion en el dataset\n",
        "* targets: placeholder del tamaño mas grande de un objetivo (entidad)\n",
        "* aspects: placeholder del tamaño mas grande de un aspecto\n",
        "* batch_size: cantidad de ejemplos de prueba utilizados en una iteracion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDtdZcZ7Ve4J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    def predict(self, sentences, targets, aspects, batch_size=None):\n",
        "        assert len(sentences) == len(targets)\n",
        "        assert len(sentences) == len(aspects)\n",
        "        \n",
        "        batches = self._get_mini_batch_start_end(len(sentences), batch_size)\n",
        "        predictions, predictions_prob = [], []\n",
        "        \n",
        "        for start, end in batches:\n",
        "            feed_dict = {\n",
        "                self._sentences: sentences[start:end], \n",
        "                self._targets: targets[start:end],\n",
        "                self._aspects: aspects[start:end],\n",
        "                self._entnet_input_keep_prob: 1.0,\n",
        "                self._entnet_output_keep_prob: 1.0,\n",
        "                self._entnet_state_keep_prob: 1.0,\n",
        "                self._final_layer_keep_prob: 1.0,\n",
        "            }\n",
        "            \n",
        "            prediction, prediction_prob = self._sess.run(\n",
        "                [self.predict_op, self.predict_proba_op],\n",
        "                feed_dict=feed_dict\n",
        "            )\n",
        "            \n",
        "            predictions.extend(prediction)\n",
        "            predictions_prob.extend(prediction_prob)\n",
        "            \n",
        "        return predictions, np.array(predictions_prob)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6T9KjO5lXOta",
        "colab_type": "text"
      },
      "source": [
        "# 9. Sentence length<br>\n",
        "\n",
        "Parametros:\n",
        "\n",
        "* sentences: oracion transformada en vectores de embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4KNn_UoVh1R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    def _sentence_length(self, sentences):\n",
        "        '''\n",
        "        sentences: (None, sentence_len, embedding_size)\n",
        "        '''\n",
        "        used = tf.sign(tf.reduce_max(tf.abs(sentences), reduction_indices=2))\n",
        "        length = tf.reduce_sum(used, reduction_indices=1)\n",
        "        length = tf.cast(length, tf.int32)\n",
        "        return length"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5Ms_LK9XkPB",
        "colab_type": "text"
      },
      "source": [
        "# =================================================="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WxEOUG7qX7-a",
        "colab_type": "text"
      },
      "source": [
        "# 10. Dynamic Memory Cell (Constructor)<br>\n",
        "\n",
        "Parametros:\n",
        "\n",
        "* (atributo) num_blocks: \n",
        "* (atributo) num_units_per_block: \n",
        "* (atributo) keys: \n",
        "* (atributo) initializer: \n",
        "* (atributo) recurrent_initializer: \n",
        "* (atributo) activation: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFbCn1cPYNjZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DynamicMemoryCell(tf.contrib.rnn.RNNCell):\n",
        "    \"\"\"\n",
        "    Implementation of a dynamic memory cell as a gated recurrent network.\n",
        "    The cell's hidden state is divided into blocks and each block's weights are tied.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 num_blocks,\n",
        "                 num_units_per_block,\n",
        "                 keys,\n",
        "                 initializer=None,\n",
        "                 recurrent_initializer=None,\n",
        "                 activation=tf.nn.relu,):\n",
        "        \n",
        "        self._num_blocks = num_blocks # M\n",
        "        self._num_units_per_block = num_units_per_block # d\n",
        "        self._keys = keys\n",
        "        self._activation = activation # \\phi\n",
        "        self._initializer = initializer\n",
        "        self._recurrent_initializer = recurrent_initializer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oIfg5kj0ZCyG",
        "colab_type": "text"
      },
      "source": [
        "# 11. State size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsAg8T4vYkqB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    @property\n",
        "    def state_size(self):\n",
        "        \"Return the total state size of the cell, across all blocks.\"\n",
        "        return self._num_blocks * self._num_units_per_block * 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0UT_-UEZF4b",
        "colab_type": "text"
      },
      "source": [
        "# 12. Output size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p93IDKnLYpB6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    @property\n",
        "    def output_size(self):\n",
        "        \"Return the total output size of the cell, across all blocks.\"\n",
        "        return self._num_blocks * self._num_units_per_block"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_aNxCySHZI8l",
        "colab_type": "text"
      },
      "source": [
        "# 13. Zero state<br>\n",
        "\n",
        "Parametros:\n",
        "\n",
        "* batch_size: \n",
        "* dtype: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6MCGTAiYuYp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    def zero_state(self, batch_size, dtype):\n",
        "        \"Initialize the memory to the key values.\"\n",
        "        zero_state = tf.concat([tf.expand_dims(key, axis=0) for key in self._keys], axis=1)\n",
        "        zero_state_batch = tf.tile(zero_state, [batch_size, 1])\n",
        "        \n",
        "        return tf.concat(\n",
        "            values=[\n",
        "                zero_state_batch,\n",
        "                tf.zeros(\n",
        "                    shape=[batch_size, self._num_blocks * self._num_units_per_block],\n",
        "                    dtype=tf.float32,\n",
        "                ),\n",
        "            ],\n",
        "            axis=1\n",
        "        )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVvVtt4lZQMM",
        "colab_type": "text"
      },
      "source": [
        "# 14. Get gate<br>\n",
        "\n",
        "Parametros:\n",
        "\n",
        "* state_j: memoria anterior a la actual\n",
        "* key_j: embedding del objetivo (entidad) de la cadena de memorias\n",
        "* inputs: palabras de la oracion de entrada\n",
        "* v: vector entrenable\n",
        "* prev_a: activacion anterior\n",
        "\n",
        "<img src=\"https://i.ibb.co/nQgMrKq/liu2018-eq2.png\" alt=\"liu2018-eq2\" border=\"0\">\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PGO6kKIYy3U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    def get_gate(self, state_j, key_j, inputs, v=None, prev_a=None):\n",
        "        \"\"\"\n",
        "        Implements the gate (scalar for each block). Equation 2:\n",
        "\n",
        "        g_j <- \\sigma(s_t^T h_j + s_t^T w_j)\n",
        "        \"\"\"\n",
        "        a = tf.reduce_sum(inputs * state_j, axis=1)\n",
        "        b = tf.reduce_sum(inputs * key_j, axis=1)\n",
        "        assert v is not None\n",
        "        c = tf.reduce_sum(prev_a * v, axis=1)\n",
        "        return tf.sigmoid(a + b + c)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmn3BbcBZU5r",
        "colab_type": "text"
      },
      "source": [
        "# 15. Get candidate<br>\n",
        "\n",
        "Parametros:\n",
        "\n",
        "* state_j: memoria anterior a la actual\n",
        "* key_j: embedding del objetivo (entidad) de la cadena de memorias\n",
        "* inputs: palabras de la oracion de entrada\n",
        "* U: matriz de parametros entrenable\n",
        "* V: matriz de parametros entrenable\n",
        "* W: matriz de parametros entrenable\n",
        "* U_bias: bias de la matriz de parametros entrenable U\n",
        "\n",
        "<img src=\"https://i.ibb.co/x7Fk6GC/liu2018-eq3y4.png\" alt=\"liu2018-eq3y4\" border=\"0\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWDGbNTiY25j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    def get_candidate(self, state_j, key_j, inputs, U, V, W, U_bias):\n",
        "        \"\"\"\n",
        "        Represents the new memory candidate that will be weighted by the\n",
        "        gate value and combined with the existing memory. Equation 3:\n",
        "\n",
        "        h_j^~ <- \\phi(U h_j + V w_j + W s_t)\n",
        "        \"\"\"\n",
        "        key_V = tf.matmul(key_j, V)\n",
        "        state_U = tf.matmul(state_j, U) + U_bias\n",
        "        inputs_W = tf.matmul(inputs, W)\n",
        "        \n",
        "        return self._activation(state_U + inputs_W + key_V)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xpD0FPFZYck",
        "colab_type": "text"
      },
      "source": [
        "# 16. Dynamic Memory Cell (Funcion)\n",
        "\n",
        "Parametros:\n",
        "\n",
        "* inputs: \n",
        "* state: \n",
        "* scope: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VMMx2PjY8a6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    def __call__(self, inputs, state, scope=None):\n",
        "        with tf.variable_scope(scope or type(self).__name__, initializer=self._initializer):\n",
        "            U = tf.get_variable('U', [self._num_units_per_block, self._num_units_per_block],\n",
        "                                initializer=self._recurrent_initializer)\n",
        "            V = tf.get_variable('V', [self._num_units_per_block, self._num_units_per_block],\n",
        "                                initializer=self._recurrent_initializer)\n",
        "            W = tf.get_variable('W', [self._num_units_per_block, self._num_units_per_block],\n",
        "                                initializer=self._recurrent_initializer)\n",
        "\n",
        "            U_bias = tf.get_variable('U_bias', [self._num_units_per_block])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMj6-IF70xlw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "            state, state_a = tf.split(\n",
        "                value=state,\n",
        "                num_or_size_splits=[\n",
        "                    self._num_blocks * self._num_units_per_block,\n",
        "                    self._num_blocks * self._num_units_per_block\n",
        "                ],\n",
        "                axis=1,\n",
        "            )\n",
        "            state_a = tf.split(state_a, self._num_blocks, axis=1)\n",
        "            assert len(state_a) == self._num_blocks"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIU8Yk-n1S2s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "            # Split the hidden state into blocks (each U, V, W are shared across blocks).\n",
        "            state = tf.split(state, self._num_blocks, axis=1)\n",
        "            assert len(state) == self._num_blocks"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XzVcIjw1XGi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "            next_states = []\n",
        "            next_a_states = []\n",
        "            for j, state_j in enumerate(state): # Hidden State (j)\n",
        "                key_j = tf.expand_dims(self._keys[j], axis=0)\n",
        "                candidate_j = self.get_candidate(state_j, key_j, inputs, U, V, W, U_bias)\n",
        "\n",
        "                reuse = False\n",
        "                if j != 0:\n",
        "                    reuse = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lX0-N9rY135W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "                with tf.variable_scope(\"entnet_gru\", reuse=reuse) as gru_scope:\n",
        "                    w_ru = tf.get_variable(\n",
        "                        \"w_ru\", \n",
        "                        [self._num_units_per_block * 2, self._num_units_per_block * 2]\n",
        "                    )\n",
        "      \n",
        "                    b_ru = tf.get_variable(\n",
        "                        \"b_ru\", [self._num_units_per_block * 2],\n",
        "                        initializer=init_ops.constant_initializer(1.0))\n",
        "        \n",
        "                    w_c = tf.get_variable(\"w_c\",\n",
        "                        [self._num_units_per_block * 2, self._num_units_per_block]\n",
        "                    )\n",
        "          \n",
        "                    b_c = tf.get_variable(\n",
        "                        \"b_c\", [self._num_units_per_block],\n",
        "                        initializer=init_ops.constant_initializer(0.0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkGHQRUk2Kma",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "                    _gru_block_cell = gen_gru_ops.gru_block_cell  # pylint: disable=invalid-name\n",
        "  \n",
        "                    _, _, _, new_a = _gru_block_cell(\n",
        "                        x=candidate_j, h_prev=state_a[j], \n",
        "                        w_ru=w_ru, w_c=w_c, b_ru=b_ru, b_c=b_c)\n",
        "                    \n",
        "                    v_a = tf.get_variable(\n",
        "                        \"v_a\", [self._num_units_per_block],\n",
        "                        initializer=self._initializer,\n",
        "                    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hlERtKE2qHO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "                next_a_states.append(new_a)\n",
        "\n",
        "                gate_j = self.get_gate(state_j, key_j, inputs, v_a, new_a)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBaxP58152oZ",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://i.ibb.co/x8P2Lsr/liu2018-eq4.png\" alt=\"liu2018-eq4\" border=\"0\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "peMM5vBz2s19",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "                # Equation 4: h_j <- h_j + g_j * h_j^~\n",
        "                # Perform an update of the hidden state (memory).\n",
        "                state_j_next = state_j + tf.expand_dims(gate_j, -1) * candidate_j"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUL6Fid32vmf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "                # Equation 5: h_j <- h_j / \\norm{h_j}\n",
        "                # Forget previous memories by normalization.\n",
        "                state_j_next_norm = tf.norm(\n",
        "                    tensor=state_j_next,\n",
        "                    ord='euclidean',\n",
        "                    axis=-1,\n",
        "                    keep_dims=True)\n",
        "                state_j_next_norm = tf.where(\n",
        "                    tf.greater(state_j_next_norm, 0.0),\n",
        "                    state_j_next_norm,\n",
        "                    tf.ones_like(state_j_next_norm))\n",
        "                state_j_next = state_j_next / state_j_next_norm\n",
        "\n",
        "                next_states.append(state_j_next)\n",
        "            \n",
        "            state_next = tf.concat(next_states, axis=1)\n",
        "            state_a_next = tf.concat(next_a_states, axis=1)\n",
        "            \n",
        "            return state_next, tf.concat(values=[state_next, state_a_next], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUdqB5kEaFS1",
        "colab_type": "text"
      },
      "source": [
        "# =================================================="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGVErlNGaGXM",
        "colab_type": "text"
      },
      "source": [
        "# 17. Zero nil slot<br>\n",
        "\n",
        "Parametros:\n",
        "\n",
        "* t: \n",
        "* name: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agMB0lJUaKJT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def zero_nil_slot(t, name=None):\n",
        "    \"\"\"\n",
        "    Overwrites the nil_slot (first row) of the input Tensor with zeros.\n",
        "\n",
        "    The nil_slot is a dummy slot and should not be trained and influence\n",
        "    the training algorithm.\n",
        "    \"\"\"\n",
        "    with name_scope(values=[t], name=name, default_name=\"zero_nil_slot\") as name:\n",
        "        t = tf.convert_to_tensor(t, name=\"t\")\n",
        "        s = tf.shape(t)[1]\n",
        "        z = tf.zeros(tf.stack([1, s]))\n",
        "        \n",
        "        return tf.concat(\n",
        "            axis=0, values=[z, tf.slice(t, [1, 0], [-1, -1])], name=name\n",
        "        )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SjTfTra_aNDy",
        "colab_type": "text"
      },
      "source": [
        "# 18. PReLU<br>\n",
        "\n",
        "Parametros:\n",
        "\n",
        "* features: \n",
        "* alpha: \n",
        "* scope: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04bOwhDTaNOz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prelu(features, alpha, scope=None):\n",
        "    \"\"\"\n",
        "    Implementation of [Parametric ReLU](https://arxiv.org/abs/1502.01852) borrowed from Keras.\n",
        "    \"\"\"\n",
        "    with tf.variable_scope(scope, 'PReLU'):\n",
        "        pos = tf.nn.relu(features)\n",
        "        neg = alpha * (features - tf.abs(features)) * 0.5\n",
        "        return pos + neg"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}